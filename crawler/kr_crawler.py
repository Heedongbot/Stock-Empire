import sys
import io
import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime
import time
import random
from openai import OpenAI
from dotenv import load_dotenv

# Force UTF-8 encoding for stdout/stderr to avoid CP949 errors on Windows
if sys.platform == "win32":
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env.local'), override=True)

class KRNewsCrawler:
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        self.output_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'public', 'kr-news-realtime.json')
        
        # OpenAI ì´ˆê¸°í™”
        api_key = os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=api_key) if api_key else None
        if self.client:
            print("[INFO] Empire KR Intelligence: ACTIVE")
        else:
            print("[WARN] OpenAI Key missing in KR Crawler. Using fallbacks.")

    def get_ai_analysis(self, title, summary):
        """
        ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì½”ë¶€ì¥ ìŠ¤íƒ€ì¼ì˜ AI ë¶„ì„ ìƒì„±
        """
        if not self.client:
            return "[ë¶„ì„ ëŒ€ê¸°] AI ì—”ì§„ ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.", 50

        try:
            prompt = f"""
            ì£¼ì‹ ë‰´ìŠ¤ ë¶„ì„:
            ì œëª©: {title}
            ìš”ì•½: {summary}

            ìœ„ ë‰´ìŠ¤ë¥¼ í•œêµ­ ì£¼ì‹ íˆ¬ìì ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”.
            1. 30ì ì´ë‚´ì˜ ì•„ì£¼ ì§§ê³  ê°•ë ¬í•œ ë¶„ì„ (ì½”ë¶€ì¥ ìŠ¤íƒ€ì¼: ì‹ ì¤‘í•˜ì§€ë§Œ ëƒ‰ì² í•˜ê²Œ)
            2. ì´ ë‰´ìŠ¤ê°€ ì£¼ê°€ì— ë¯¸ì¹  ì˜í–¥ ì ìˆ˜ (0~100)

            ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
            {{"insight": "ë¶„ì„ë‚´ìš©", "score": 85}}
            """
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ Stock Empireì˜ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ 'ì½”ë¶€ì¥'ì…ë‹ˆë‹¤."},
                          {"role": "user", "content": prompt}],
                max_tokens=150,
                temperature=0.3,
                response_format={ "type": "json_object" }
            )
            res = json.loads(response.choices[0].message.content)
            return res.get("insight", ""), res.get("score", 50)
        except Exception as e:
            print(f"[ERROR] AI Analysis failed: {e}")
            return "ì‹œì¥ ìƒí™© ëª¨ë‹ˆí„°ë§ ì¤‘ì…ë‹ˆë‹¤.", 50

    def crawl(self):
        url = "https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258"
        news_list = []
        
        print(f"[{datetime.now()}] ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")

        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = soup.select('ul.realtimeNewsList li')

            for article in articles[:10]: # ìµœì‹  ë‰´ìŠ¤ 10ê°œë§Œ ì§‘ì¤‘ ë¶„ì„
                title_tag = article.select_one('dd.articleSubject a') or article.select_one('dt a')
                if not title_tag: continue

                title = title_tag.get_text(strip=True)
                link = "https://finance.naver.com" + title_tag['href']
                summary_tag = article.select_one('dl > dd.articleSummary')
                summary = summary_tag.get_text(strip=True) if summary_tag else ""
                press = (article.select_one('span.press') or article.select_one('span.wdate')).get_text(strip=True)

                # AI ë¶„ì„ ì‹¤í–‰
                insight, score = self.get_ai_analysis(title, summary)

                news_data = {
                    "id": str(hash(link)),
                    "market": "KR",
                    "ticker": "KOSPI",
                    "sentiment": "BULLISH" if score > 55 else "BEARISH" if score < 45 else "NEUTRAL",
                    "published_at": str(datetime.now()),
                    "free_tier": {
                        "title": title,
                        "summary_kr": summary,
                        "link": link,
                        "original_source": press
                    },
                    "vip_tier": {
                        "ai_analysis": {
                            "summary_kr": insight,
                            "impact_score": score,
                            "investment_insight": "ì‹¤ì‹œê°„ ìˆ˜ê¸‰ ë°ì´í„° ê¸°ë°˜ ëŒ€ì‘ ê¶Œì¥"
                        }
                    }
                }
                news_list.append(news_data)

            # íŒŒì¼ ì €ì¥
            os.makedirs(os.path.dirname(self.output_path), exist_ok=True)
            with open(self.output_path, "w", encoding="utf-8") as f:
                json.dump(news_list, f, indent=2, ensure_ascii=False)
            print(f"[{datetime.now()}] {len(news_list)}ê°œì˜ í•œêµ­ ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë¨.")

            # ------------------------------------------------------------------
            # [ìë™ í¬ìŠ¤íŒ…] í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ë°œí–‰
            # ------------------------------------------------------------------
            if news_list:
                try:
                    # ìƒëŒ€ ê²½ë¡œ/ì ˆëŒ€ ê²½ë¡œ import í˜¸í™˜ì„± ì²˜ë¦¬
                    try:
                        from crawler.tistory_poster import TistoryAutoPoster
                    except ImportError:
                        from tistory_poster import TistoryAutoPoster
                        
                    print("[INFO] Starting Tistory Auto-Posting...")
                    
                    # ê°€ì¥ ìµœì‹  ì¤‘ìš” ë‰´ìŠ¤ 1ê°œ ì„ ì •
                    top_news = news_list[0]
                    
                    # ë¸”ë¡œê·¸ìš© ì œëª© ë° ë³¸ë¬¸ ìƒì„± (HTML í¬ë§·)
                    blog_title = f"[Stock Empire] ğŸš¨ ê¸´ê¸‰: {top_news['free_tier']['title']}"
                    
                    # AI ë¶„ì„ ë‚´ìš©ì´ ì—†ì„ ê²½ìš° ëŒ€ë¹„
                    ai_score = top_news['vip_tier'].get('ai_analysis', {}).get('impact_score', 50)
                    ai_summary = top_news['vip_tier'].get('ai_analysis', {}).get('summary_kr', 'AI ë¶„ì„ ë°ì´í„° ì—†ìŒ')
                    
                    blog_content = f"""
                    <h2 style="color: #333; border-bottom: 2px solid #0056b3; padding-bottom: 10px;">ğŸ“‰ ì‹œì¥ë¶„ì„ ë¦¬í¬íŠ¸</h2>
                    <p>ì•ˆë…•í•˜ì„¸ìš”, <strong>Stock Empire</strong>ì˜ ì¸ê³µì§€ëŠ¥ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.</p>
                    <p>í˜„ì¬ ì‹œì¥ì—ì„œ ê°€ì¥ ì£¼ëª©í•´ì•¼ í•  ë‰´ìŠ¤ë¥¼ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤.</p>
                    <br>
                    
                    <h3 style="background-color: #f8f9fa; padding: 10px;">ğŸ“° {top_news['free_tier']['title']}</h3>
                    <p style="font-size: 16px; line-height: 1.6;">
                    {top_news['free_tier']['summary_kr']}
                    </p>
                    <br>
                    
                    <div style="border: 1px solid #ddd; padding: 15px; border-radius: 8px; background-color: #f1f8ff;">
                        <h4 style="margin-top: 0; color: #0056b3;">ğŸ¤– AI ë¯¼ê°ë„ ë¶„ì„</h4>
                        <ul style="list-style-type: none; padding-left: 0;">
                            <li><strong>ğŸ¯ ì˜í–¥ë ¥ ì ìˆ˜:</strong> {ai_score}/100</li>
                            <li><strong>ğŸ“¢ ì‹œì¥ ë¶„ìœ„ê¸°:</strong> {top_news['sentiment']}</li>
                            <li><strong>ğŸ’¡ í•œì¤„ í‰:</strong> {ai_summary}</li>
                        </ul>
                    </div>
                    
                    <br>
                    <p style="color: #888; font-size: 12px;">â€» ë³¸ ë¦¬í¬íŠ¸ëŠ” AIì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìœ¼ë©° íˆ¬ìì˜ ì±…ì„ì€ ë³¸ì¸ì—ê²Œ ìˆìŠµë‹ˆë‹¤.</p>
                    <hr>
                    <p align="center">
                        <a href="{top_news['free_tier']['link']}" target="_blank" style="background-color: #0056b3; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px;">ì›ë¬¸ ê¸°ì‚¬ ë³´ëŸ¬ê°€ê¸°</a>
                    </p>
                    """
                    
                    # íƒœê·¸ ìƒì„±
                    tags = ["ì£¼ì‹", "ì¦ì‹œ", "ì½”ìŠ¤í”¼", "StockEmpire", "ìë™í¬ìŠ¤íŒ…"]
                    
                    # í¬ìŠ¤íŒ… ì‹¤í–‰
                    poster = TistoryAutoPoster()
                    poster.setup_driver()
                    if poster.login():
                        poster.post(title=blog_title, content=blog_content, tags=",".join(tags))
                    poster.close()
                    
                except Exception as e:
                    print(f"[ERROR] Auto-posting failed: {e}")

        except Exception as e:
            print(f"Error: {e}")
            
if __name__ == "__main__":
    crawler = KRNewsCrawler()
    print("Stock Empire KR Crawler Started (Interval: 30min)")
    while True:
        try:
            crawler.crawl()
        except Exception as e:
            print(f"[ERROR] Main loop error: {e}")
        time.sleep(1800)
