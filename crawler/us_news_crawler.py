"""
US Stock News Crawler (Live & Translated)
- Source: Yahoo Finance RSS, Investing.com
- Feature: Korean Translation, Breaking News Detection, 30-min Interval
"""

import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime
import time
import random
from deep_translator import GoogleTranslator
from openai import OpenAI
from dotenv import load_dotenv

# Load local environment variables
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env.local'), override=True)

class StockNewsCrawler:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/rss+xml, application/xml, text/xml, */*'
        }
        self.output_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'public', 'us-news-realtime.json')
        self.translator = GoogleTranslator(source='auto', target='ko')
        self.cached_ids = set()
        
        # Initialize OpenAI if key exists
        api_key = os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=api_key) if api_key else None
        if self.client:
            print("[INFO] OpenAI Intelligence Engine: ACTIVE")
        else:
            print("[WARN] OpenAI Key missing. Falling back to Heuristic Reasoning.")

    def translate(self, text):
        try:
            if not text: return ""
            # Prevent translating short technical terms that should remain English
            upper_text = text.strip().upper()
            if len(upper_text) < 5 and upper_text.isalpha():
                return upper_text
            return self.translator.translate(text)
        except Exception as e:
            print(f"[WARN] Translation failed: {e}")
            return text

    def get_ai_insight(self, title, summary, source, sentiment):
        """
        Generates professional investment insight using GPT-4o-mini
        """
        if not self.client:
            return None
            
        try:
            prompt = f"""
            Analyze the following financial news for an elite investment dashboard:
            Source: {source}
            Title: {title}
            Summary: {summary}
            Detected Sentiment: {sentiment}

            Task: Provide a deep, professional investment insight in 1-2 Korean sentences. 
            Do NOT repeat the title. Focus on 'Why this matters' and 'Market implication'.
            Tone: Professional, Cold, Analytical (like a top-tier hedge fund report).
            Avoid: "ì•ˆë…•í•˜ì„¸ìš”", "ë¶„ì„ ê²°ê³¼", "ìš”ì•½í•˜ìë©´" - start directly with the core insight.
            """
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "system", "content": "You are a senior equity analyst at Stock Empire."},
                          {"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"[ERROR] AI Insight generation failed: {e}")
            return None

    def crawl_all_sources(self, limit=20):
        print(f"[{datetime.now().strftime('%H:%M:%S')}] Crawling Unified Global Market Sources...")
        news_list = []
        sources = [
            {'name': 'Yahoo Finance', 'url': 'https://finance.yahoo.com/news/rssindex'},
            {'name': 'Investing.com', 'url': 'https://www.investing.com/rss/news_25.rss'},
            {'name': 'MarketWatch', 'url': 'https://www.marketwatch.com/rss/topstories'},
            {'name': 'Reuters (Finance)', 'url': 'https://www.reutersagency.com/feed/?best-topics=business-finance&post_type=best'}
        ]
        
        for src in sources:
            try:
                print(f" -> Fetching {src['name']}...")
                response = requests.get(src['url'], headers=self.headers, timeout=10)
                if response.status_code != 200: continue
                    
                soup = BeautifulSoup(response.content, 'xml')
                items = soup.find_all('item', limit=20) # Expanded pool for better selection
                
                for item in items:
                    title = item.find('title').text.strip()
                    link = item.find('link').text.strip()
                    desc = item.find('description').text.strip() if item.find('description') else title
                    pub_date_raw = item.find('pubDate').text.strip() if item.find('pubDate') else None
                    
                    # --- [NEW] FACT-GATE: DATE VALIDATION ---
                    if pub_date_raw:
                        try:
                            # Handling various date formats
                            from dateutil import parser
                            try:
                                pub_dt = parser.parse(pub_date_raw)
                            except:
                                import email.utils
                                pub_dt = email.utils.parsedate_to_datetime(pub_date_raw)
                                
                            if pub_dt.tzinfo is None:
                                pub_dt = pub_dt.replace(tzinfo=datetime.now().astimezone().tzinfo)
                                
                            now_dt = datetime.now(pub_dt.tzinfo)
                            diff = now_dt - pub_dt
                            
                            if diff.days > 3:
                                # print(f" [SKIP] Old News: {title[:30]}...")
                                continue
                        except Exception as e:
                            print(f" [WARN] Date Parse Error: {pub_date_raw} -> {e}")
                            pub_dt = datetime.now()

                    # --- NOISE & RETAIL DRAMA FILTER ---
                    # Discarding non-institutional/noise news that doesn't affect the Stock Empire
                    noise_keywords = [
                        'prison', 'mom of', 'divorce', 'ramsey', 'lifestyle', 'family',
                        'personal finance', 'how to save', 'scam', 'police', 'accident',
                        'parenting', 'celebrity', 'wedding', 'dating', 'inheritance',
                        'newsletter', 'subscribe', 'sign up', 'exclusive offer', 'free brief',
                        'what does this mean', 'should you buy', 'is it time to', 'why is it',
                        'barchart brief', 'motley fool', 'zacks', 'analyst report:',
                        'pity', 'investors who', 'how i lost', 'story of', 'unlucky',
                        'bitcoin', 'crypto', 'altcoin', 'meme coin', 'doge', 'shiba',
                        'sob story', 'failed', 'bankrupt individual'
                    ]
                    content_to_check = (title + " " + desc).lower()
                    if any(x in content_to_check for x in noise_keywords) or title.strip().endswith('?'):
                        continue
                        
                    pub_date = pub_date_raw if pub_date_raw else datetime.now().isoformat()
                    formatted = self._format_news_item(title, desc, link, pub_date, src['name'])
                    if formatted:
                        news_list.append(formatted)
                    
            except Exception as e:
                print(f"[WARN] {src['name']} error: {e}")
                
        # Shuffle to mix sources
        random.shuffle(news_list)
        return news_list[:limit]

    def _format_news_item(self, title, summary, link, date, source):
        # 1. Financial Term Correction (Fix bad machine translation)
        term_map = {
            'Earnings Call': 'ì‹¤ì  ë°œí‘œ ì»¨í¼ëŸ°ìŠ¤ ì½œ',
            'Transcript': 'íšŒì˜ë¡/ìŠ¤í¬ë¦½íŠ¸',
            'Revenue': 'ë§¤ì¶œì•¡',
            'Net Income': 'ë‹¹ê¸°ìˆœì´ìµ',
            'EPS': 'ì£¼ë‹¹ìˆœì´ìµ(EPS)',
            'Beat': 'ì˜ˆìƒì¹˜ ìƒíšŒ(ì–´ë‹ ì„œí”„ë¼ì´ì¦ˆ)',
            'Miss': 'ì˜ˆìƒì¹˜ í•˜íšŒ(ì–´ë‹ ì‡¼í¬)',
            'Guidance': 'í–¥í›„ ì‹¤ì  ê°€ì´ë“œë¼ì¸',
            'Dow Jones': 'ë‹¤ìš° ì¡´ìŠ¤ ì§€ìˆ˜',
            'S&P 500': 'S&P 500 ì§€ìˆ˜',
            'Nasdaq': 'ë‚˜ìŠ¤ë‹¥ ì§€ìˆ˜',
            'Quarterly': 'ë¶„ê¸°ë³„',
            'Common Stock': 'ë³´í†µì£¼',
            'Selling': 'ë§¤ê°/ë§¤ë„',
            'Dilution': 'ì£¼ì£¼ê°€ì¹˜ í¬ì„',
            'Buyback': 'ìì‚¬ì£¼ ë§¤ì…',
            'Dividend': 'ë°°ë‹¹ê¸ˆ',
            'Rate Hike': 'ê¸ˆë¦¬ ì¸ìƒ',
            'Rate Cut': 'ê¸ˆë¦¬ ì¸í•˜',
            'Short Squeeze': 'ìˆìŠ¤í€´ì¦ˆ(ê³µë§¤ë„ ì••ë°•)',
            'Bull Run': 'ìƒìŠ¹ ë ë¦¬',
            'Bear Market': 'í•˜ë½ì¥',
            'Yield': 'ì±„ê¶Œ ìˆ˜ìµë¥ ',
            'Inflation': 'ì¸í”Œë ˆì´ì…˜(ë¬¼ê°€ ìƒìŠ¹)'
        }
        
        keywords = (title + " " + summary).lower()
        
        # 2. Advanced Sentiment & Context Analysis
        sentiment = "NEUTRAL"
        # ALPHA CONVICTION FILTER (THE "MONEY" GATEKEEPER)
        alpha_keywords = [
            'upgrade', 'downgrade', 'price target', 'guidance', 'acquisition', 'merger',
            'earnings beat', 'earnings miss', 'buyback', 'dividend', 'fda', 'sec', 
            'settlement', 'contract', 'partnership', 'massive', 'breakout', 'deal',
            'insider buy', 'tender offer', 'spinoff', 'ipo', 'outlook', 'forecast',
            'expansion', 'investment', 'regulatory', 'monetary', 'strategy', 'revenue'
        ]
        
        major_tickers = [
            'nvda', 'tsla', 'aapl', 'msft', 'goog', 'amd', 'meta', 'amzn', 'nflx', 'avgo',
            'asml', 'trmp', 'pltr', 'smci', 'arm', 'mu', 'mstr', 'coin', 'ibm', 'intc', 'v', 'ma', 'jpm'
        ]

        has_alpha = any(x in keywords for x in alpha_keywords)
        has_major_ticker = any(f" {t} " in f" {keywords} " or keywords.startswith(t) for t in major_tickers)
        
        # Bullish Clusters
        bull_weights = ['rise', 'jump', 'soar', 'surge', 'gain', 'high', 'bull', 'growth', 'profit', 'up', 'record', 'outperform', 'buyback', 'dividend', 'expand', 'beat', 'exceed', 'positive', 'upgrade', 'all-time high']
        # Bearish Clusters
        bear_weights = ['fall', 'drop', 'plunge', 'sink', 'loss', 'low', 'bear', 'crash', 'down', 'crisis', 'risk', 'underperform', 'dilution', 'offering', 'sell stock', 'debt', 'layoff', 'cut', 'disposal', 'scandal', 'lawsuit', 'sell', 'sold']
        
        # 1. Macro Breaking Detection (Always bypasses filter)
        is_breaking = False
        macro_indicators = ['fomc', 'fed', 'cpi', 'pce', 'gdp', 'payrolls', 'unemployment', 'inflation', 'rate hike', 'rate cut']
        if any(x in keywords for x in macro_indicators):
            is_breaking = True

        # 2. Heuristic Sentiment Analysis
        bull_score = sum(1 for x in bull_weights if x in keywords)
        bear_score = sum(1 for x in bear_weights if x in keywords)

        # 3. ALPHA GATEKEEPER - Only keep if it's Macro OR has Alpha Keyword OR Significant Ticker move
        if not is_breaking:
            if not has_alpha:
                if not (has_major_ticker and (bull_score >= 1 or bear_score >= 1)):
                    return None # Drop noise/low-impact news
        
        # Determine specific sentiment
        if bull_score > bear_score: sentiment = "BULLISH"
        elif bear_score > bull_score: sentiment = "BEARISH"
        else: sentiment = "NEUTRAL"

        # 4. Filter Calibration
        if not is_breaking and bull_score == 0 and bear_score == 0:
            return None # Toss generic fluff

        # 5. Translation with Term Mapping
        title_kr = self.translate(title)
        for en, kr in term_map.items():
            title_kr = title_kr.replace(en, kr)
            title_kr = title_kr.replace("ìˆ˜ì… í†µí™”", "ì‹¤ì  ë°œí‘œ")
            title_kr = title_kr.replace("ìˆ˜ì… ì „í™”", "ì‹¤ì  ë°œí‘œ")
            
        summary_kr = self.translate(summary[:300])
        
        # 6. Empire AI Dynamic Reasoning (Prioritize OpenAI)
        ai_insight = self.get_ai_insight(title, summary, source, sentiment)
        
        if not ai_insight:
            # Fallback to High-Quality Institutional Reasoning
            impact_score = min(94, 58 + (max(bull_score, bear_score) * 7) + random.randint(0, 5))
            
            if sentiment == "BULLISH":
                if 'upgrade' in keywords or 'price target' in keywords:
                    ai_insight = f"[ë¯¸ì¥ ì†ë³´ ë¶„ì„] ì£¼ìš” íˆ¬ìì€í–‰(IB)ì˜ íˆ¬ìì˜ê²¬ ìƒí–¥ì€ ê¸°ê´€ ìê¸ˆ ìœ ì…ì˜ ê°•ë ¥í•œ íŠ¸ë¦¬ê±°ì…ë‹ˆë‹¤. í˜„ì¬ ì°¨íŠ¸ìƒ ì£¼ìš” ì§€ì§€ì„ ì„ í™•ë³´í•œ ìƒíƒœë¡œ, ë‹¨ê¸°ì ìœ¼ë¡œ ì•½ 10~15%ì˜ ì—…ì‚¬ì´ë“œê°€ ì—´ë ¤ ìˆìŠµë‹ˆë‹¤. í•œêµ­ íˆ¬ììë“¤ì€ í™˜ìœ¨ ë³€ë™ì„±ì„ ê³ ë ¤í•˜ì—¬ ì‹¤ì‹œê°„ ë¶„í•  ë§¤ìˆ˜ ê´€ì ì´ ìœ íš¨í•©ë‹ˆë‹¤."
                elif 'beat' in keywords or 'guidance' in keywords:
                    ai_insight = f"[ì–´ë‹ ì„œí”„ë¼ì´ì¦ˆ] ì˜ˆìƒì¹˜ë¥¼ ìƒíšŒí•˜ëŠ” ì‹¤ì  ê°€ì´ë“œë¼ì¸ì€ í€ë”ë©˜í„¸ì˜ ê³ ì„±ì¥ì„ ì¦ëª…í•©ë‹ˆë‹¤. ë‹¨ìˆœ ë“±ë½ì„ ë– ë‚˜ ì£¼ê°€ ì¬í‰ê°€(Re-rating)ê°€ ì‹œì‘ë˜ëŠ” êµ¬ê°„ì´ë¯€ë¡œ, ì¥ê¸°ì  ì„±ì¥ì´ ê¸°ëŒ€ë˜ëŠ” ì£¼ë„ì£¼ ì¤‘ì‹¬ì˜ ë¹„ì¤‘ í™•ëŒ€ ì „ëµì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                else:
                    ai_insight = f"[ì½”ë¶€ì¥ ì „ë¬¸ ì˜ê²¬] ì‹œì¥ì˜ ê°•ë ¥í•œ ë§¤ìˆ˜ì„¸ê°€ í™•ì¸ë˜ëŠ” ìœ ì˜ë¯¸í•œ ì‹œê·¸ë„ì…ë‹ˆë‹¤. íŠ¹íˆ ë‚˜ìŠ¤ë‹¥ ì„ ë¬¼ ì§€ìˆ˜ì˜ íë¦„ê³¼ ë™ì¡°í™”ë˜ê³  ìˆì–´, ì¶”ì„¸ ì¶”ì¢… ë§¤ë§¤(Trend Following) ì „ëµì´ ë§¤ìš° ìœ ë¦¬í•œ êµ¬ê°„ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤."
            elif sentiment == "BEARISH":
                if 'offering' in keywords or 'dilution' in keywords or 'sell' in keywords:
                    ai_insight = f"[ë¦¬ìŠ¤í¬ ê°ì§€] ìœ ìƒì¦ì ë° ì£¼ì£¼ê°€ì¹˜ í¬ì„ ì†Œì‹ì€ ê¸°ê´€ë“¤ì˜ ì´íƒˆ ì‹ í˜¸ì…ë‹ˆë‹¤. Empire AIëŠ” ì´ë¥¼ ê°•ë ¥í•œ í•˜ë°© ë³€ê³¡ì ìœ¼ë¡œ ë¶„ì„í•˜ë©°, ì„±ê¸‰í•œ ì €ê°€ ë§¤ìˆ˜ë³´ë‹¤ëŠ” í˜„ê¸ˆ ë¹„ì¤‘ì„ ëŠ˜ë ¤ ë¦¬ìŠ¤í¬ë¥¼ ì„ ì œì ìœ¼ë¡œ ê´€ë¦¬í•  ê²ƒì„ ê°•ë ¥ ê¶Œê³ í•©ë‹ˆë‹¤."
                elif 'crash' in keywords or 'sink' in keywords:
                    ai_insight = f"[ê¸´ê¸‰ ì‹œí™©] íŒ¨ë‹‰ ì…€(Panic Sell) ë¬¼ëŸ‰ì´ ì¶œíšŒë˜ë©° íˆ¬ì‹¬ì´ ê¸‰ê²©íˆ ì–¼ì–´ë¶™ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ì´ë™í‰ê· ì„ ì´ ë¬´ë„ˆì§„ ìƒíƒœì´ë¯€ë¡œ, ë°”ë‹¥ê¶Œì´ í™•ì¸ë  ë•Œê¹Œì§€ëŠ” ë³´ìˆ˜ì ì¸ ê´€ì ì—ì„œ ê´€ë§í•˜ë˜, ë‚™í­ ê³¼ëŒ€ì£¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì—…í•  ì‹œê¸°ì…ë‹ˆë‹¤."
                else:
                    ai_insight = f"[ì½”ë¶€ì¥ ì£¼ì˜ë³´] ì‹œì¥ì˜ í•˜ë°© ì••ë ¥ì´ ê°€ì†í™”ë˜ëŠ” ë¶€ì •ì  ë³€ë™ì„±ì´ í¬ì°©ë©ë‹ˆë‹¤. ë¯¸ êµ­ì±„ ê¸ˆë¦¬ ë³€ë™ê³¼ í•¨ê»˜ ë³´ìˆ˜ì ì¸ í¬ì§€ì…˜ ìœ ì§€ê°€ í•„ìš”í•˜ë©°, ë³€ë™ì„±ì´ ì¦ì•„ë“¤ ë•Œê¹Œì§€ëŠ” ì¶”ê°€ ë§¤ìˆ˜ë¥¼ ìì œí•˜ì‹­ì‹œì˜¤."
            else:
                if any(x in keywords for x in macro_indicators):
                    ai_insight = f"[ê±°ì‹œ ì§€í‘œ ë¸Œë¦¬í•‘] FOMC/CPI ë“± ì£¼ìš” ê±°ì‹œ ì§€í‘œ ë°œí‘œë¥¼ ì•ë‘ê³  ì‹œì¥ì˜ ê²½ê³„ê°ì´ í™•ì‚°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì§€í‘œ ê²°ê³¼ì— ë”°ë¼ ë¯¸ ì¦ì‹œ ë°©í–¥ì„±ì´ í¬ê²Œ ê°ˆë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë°œí‘œ ì „ê¹Œì§€ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ì˜ ë³€ë™ì„±ì„ ì¤„ì´ëŠ” ë°©ì–´ì  í¬ì§€ì…˜ì´ ìœ ë¦¬í•©ë‹ˆë‹¤."
                else:
                    ai_insight = "[ì‹œí™© íƒìƒ‰] ê±°ì‹œì  ë¶ˆí™•ì‹¤ì„±ìœ¼ë¡œ ì¸í•´ ì‹œì¥ì´ ë°©í–¥ì„±ì„ íƒìƒ‰í•˜ëŠ” ì¤‘ë¦½ êµ¬ê°„ì…ë‹ˆë‹¤. ì£¼ìš” ë³€ê³¡ì  ëŒíŒŒë¥¼ í™•ì¸í•˜ê¸° ì „ê¹Œì§€ëŠ” ê³µê²©ì ì¸ ë² íŒ…ë³´ë‹¤ëŠ” ì†ŒëŸ‰ ë¶„í•  ë§¤ë§¤ë¡œ ëŒ€ì‘í•˜ëŠ” ê²ƒì´ í˜„ëª…í•©ë‹ˆë‹¤."
        else:
            # AI insight was successful, calculate a better impact score
            impact_score = min(98, 70 + (max(bull_score, bear_score) * 4) + random.randint(0, 5))
            if is_breaking: impact_score = 99 # Institutional Priority

        return {
            'id': str(hash(link)),
            'ticker': 'US Market',
            'sentiment': sentiment,
            'is_breaking': is_breaking,
            'published_at': date,
            'free_tier': {
                'title': title_kr,
                'title_en': title,
                'summary_kr': summary_kr + "..." if len(summary_kr) > 200 else summary_kr,
                'link': link,
                'original_source': source
            },
            'vip_tier': {
                'ai_analysis': {
                    'summary_kr': ai_insight,
                    'impact_score': impact_score
                },
                'trading_strategy': {
                    'action': "ë§¤ìˆ˜" if sentiment == "BULLISH" else "ë§¤ë„" if sentiment == "BEARISH" else "ê´€ë§",
                    'target_price': "VIP ì „ìš©",
                    'stop_loss': "VIP ì „ìš©"
                }
            }
        }

    def save(self, data):
        if not data: return
        clean_data = [item for item in data if item is not None]
        os.makedirs(os.path.dirname(self.output_path), exist_ok=True)
        with open(self.output_path, 'w', encoding='utf-8') as f:
            json.dump(clean_data, f, ensure_ascii=False, indent=2)
        print(f"[{datetime.now().strftime('%H:%M:%S')}] Saved {len(clean_data)} items to {self.output_path}")

        # ------------------------------------------------------------------
        # [ìë™ í¬ìŠ¤íŒ…] í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ë°œí–‰ (ë¯¸êµ­ ì£¼ì‹ ë²„ì „)
        # ------------------------------------------------------------------
        if clean_data:
            try:
                # ìƒëŒ€ ê²½ë¡œ/ì ˆëŒ€ ê²½ë¡œ import í˜¸í™˜ì„± ì²˜ë¦¬
                try:
                    from crawler.tistory_poster import TistoryAutoPoster
                except ImportError:
                    from tistory_poster import TistoryAutoPoster
                
                print("[INFO] Starting Tistory Auto-Posting (US Market)...")
                
                # ê°€ì¥ í•«í•œ ë‰´ìŠ¤ 1ê°œ ì„ ì • (Breaking News ìš°ì„ , ì—†ìœ¼ë©´ ì²«ë²ˆì§¸)
                top_news = next((item for item in clean_data if item.get('is_breaking')), clean_data[0])
                
                # ë°ì´í„° ì¶”ì¶œ
                title_kr = top_news['free_tier']['title']
                summary_kr = top_news['free_tier']['summary_kr']
                ai_summary = top_news['vip_tier']['ai_analysis']['summary_kr']
                impact_score = top_news['vip_tier']['ai_analysis']['impact_score']
                sentiment = top_news['sentiment']
                
                # ë¸”ë¡œê·¸ìš© ì œëª© (ì´ëª¨ì§€ í¬í•¨)
                blog_title = f"[Stock Empire] ğŸ‡ºğŸ‡¸ ë¯¸ì¥ ì†ë³´: {title_kr}"
                
                # ë¸”ë¡œê·¸ ë³¸ë¬¸ (HTML + í™ë³´ ë§í¬)
                blog_content = f"""
                <h2 style="color: #0F172A; border-bottom: 2px solid #2563EB; padding-bottom: 10px;">ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì¦ì‹œ AI ì†ë³´</h2>
                <p><strong>Stock Empire AI</strong>ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ í¬ì°©í•œ ë¯¸êµ­ ì‹œì¥ í•µì‹¬ ë‰´ìŠ¤ì…ë‹ˆë‹¤.</p>
                <br>
                
                <h3 style="background-color: #EFF6FF; padding: 15px; border-left: 5px solid #2563EB;">ğŸ“° {title_kr}</h3>
                <p style="font-size: 16px; line-height: 1.7; color: #334155;">
                {summary_kr}
                </p>
                <br>
                
                <div style="border: 1px solid #E2E8F0; padding: 20px; border-radius: 12px; background-color: #F8FAFC;">
                    <h4 style="margin-top: 0; color: #2563EB;">ğŸ¤– AI ì›Œë£¸(War Room) ë¶„ì„</h4>
                    <ul style="list-style-type: none; padding-left: 0; margin-bottom: 0;">
                        <li style="margin-bottom: 8px;"><strong>âš¡ íŒŒê¸‰ë ¥ ì ìˆ˜:</strong> <span style="background-color: #FEF3C7; padding: 2px 6px; border-radius: 4px;">{impact_score}/100</span></li>
                        <li style="margin-bottom: 8px;"><strong>ğŸŒŠ ì‹œì¥ ê°ì§€:</strong> {sentiment}</li>
                        <li style="margin-top: 12px; font-weight: bold; color: #0F172A;">ğŸ’¡ ì½”ë¶€ì¥ Insight:</li>
                        <li style="color: #475569; padding-left: 10px; border-left: 3px solid #CBD5E1;">{ai_summary}</li>
                    </ul>
                </div>
                
                <br>
                <hr style="border: 0; border-top: 1px dashed #CBD5E1; margin: 30px 0;">
                
                <!-- íŠ¸ë˜í”½ ìœ ì…ìš© í™ë³´ ì„¹ì…˜ -->
                <div style="text-align: center; background: linear-gradient(135deg, #1e293b 0%, #0f172a 100%); padding: 30px 20px; border-radius: 15px; color: white;">
                    <h3 style="color: #60A5FA; margin-top: 0;">ğŸš€ ì•„ì§ë„ ë‰´ìŠ¤ë¥¼ ì§ì ‘ ì°¾ìœ¼ì‹œë‚˜ìš”?</h3>
                    <p style="margin-bottom: 25px; color: #94A3B8;">
                        <strong>Stock Empire</strong>ì—ì„œëŠ” ì „ ì„¸ê³„ ê¸ˆìœµ ë‰´ìŠ¤ë¥¼ AIê°€ 24ì‹œê°„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤.<br>
                        ì§€ê¸ˆ ë°”ë¡œ ì ‘ì†í•´ì„œ <strong>ë‚˜ë§Œì˜ AI íˆ¬ì ë¹„ì„œ</strong>ë¥¼ ë§Œë‚˜ë³´ì„¸ìš”.
                    </p>
                    <a href="https://stock-empire.vercel.app" target="_blank" 
                       style="background-color: #3B82F6; color: white; padding: 15px 30px; text-decoration: none; border-radius: 30px; font-weight: bold; font-size: 18px; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);">
                       ğŸ‘‰ Stock Empire ë¬´ë£Œ ì‚¬ìš©í•˜ê¸°
                    </a>
                </div>
                <br>
                <p style="color: #94A3B8; font-size: 11px; text-align: center;">â€» ë³¸ í¬ìŠ¤íŒ…ì€ Stock Empire AI ì—”ì§„ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
                """
                
                # íƒœê·¸
                tags = ["ë¯¸êµ­ì£¼ì‹", "ë‚˜ìŠ¤ë‹¥", "S&P500", "StockEmpire", "AIíˆ¬ì", "í•´ì™¸ì£¼ì‹"]
                
                # í¬ìŠ¤íŒ… ì‹¤í–‰
                poster = TistoryAutoPoster()
                poster.post(title=blog_title, content=blog_content, tags=tags)
                
            except Exception as e:
                print(f"[ERROR] US Auto-posting failed: {e}")

def main():
    crawler = StockNewsCrawler()
    print("Stock Empire Crawler Started (Interval: 30min)")
    print("Press Ctrl+C to stop.")
    
    while True:
        try:
            news = crawler.crawl_all_sources(limit=15)
            crawler.save(news)
        except Exception as e:
            print(f"[ERROR] Main loop error: {e}")
        
        # Wait 30 minutes
        print("Waiting 30 minutes...")
        time.sleep(1800) 

if __name__ == "__main__":
    main()
